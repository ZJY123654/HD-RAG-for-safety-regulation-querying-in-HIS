{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3108abc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import pandas as pd\n",
    "import time\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "from ragas.dataset_schema import SingleTurnSample\n",
    "from ragas.metrics import (\n",
    "    LLMContextPrecisionWithoutReference,\n",
    "    ContextRelevance,\n",
    "    AnswerAccuracy,\n",
    "    SemanticSimilarity,\n",
    "    Faithfulness\n",
    ")\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "# 设置 API Key 和 Base URL\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your api key\"\n",
    "\n",
    "# 创建 LangChain LLM 实例，支持自定义 base_url\n",
    "llm_instance = ChatOpenAI(\n",
    "    model=\"deepseek-chat\",\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    base_url=\"your base url\",\n",
    ")\n",
    "\n",
    "# 包装成 Ragas LLM\n",
    "evaluator_llm = LangchainLLMWrapper(llm_instance)\n",
    "\n",
    "# 创建 LangChain 嵌入实例，使用 text-embedding-3-small 模型\n",
    "evaluator_embedding = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    base_url=\"your base url\",\n",
    ")\n",
    "\n",
    "# 包装成 Ragas 嵌入\n",
    "evaluator_embeddings_wrapper = LangchainEmbeddingsWrapper(evaluator_embedding)\n",
    "\n",
    "async def main():\n",
    "    # 读取输入 CSV 文件\n",
    "    input_file = 'merged_test_dataset.csv'\n",
    "    df = pd.read_csv(input_file)\n",
    "\n",
    "    # 创建评估器（在循环外创建以复用）\n",
    "    context_precision = LLMContextPrecisionWithoutReference(llm=evaluator_llm)\n",
    "    scorer_relevance = ContextRelevance(llm=evaluator_llm)\n",
    "    scorer_accuracy = AnswerAccuracy(llm=evaluator_llm)\n",
    "    scorer_similarity = SemanticSimilarity(embeddings=evaluator_embeddings_wrapper)\n",
    "    scorer_faithfulness = Faithfulness(llm=evaluator_llm)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df), desc=\"评估进度\"):\n",
    "        start_time = time.time()\n",
    "\n",
    "        user_input = row['Query']\n",
    "        reference = row['Ground_truth']\n",
    "        response = row['Response']\n",
    "        retrieved_context_str = row['Retrievaled_context']\n",
    "\n",
    "        # 尝试解析 retrieved_contexts 为列表，如果失败则视为单个字符串的列表\n",
    "        try:\n",
    "            retrieved_contexts = ast.literal_eval(retrieved_context_str)\n",
    "            if not isinstance(retrieved_contexts, list):\n",
    "                retrieved_contexts = [retrieved_context_str]\n",
    "        except:\n",
    "            retrieved_contexts = [retrieved_context_str]\n",
    "\n",
    "        # 创建样本并计算分数\n",
    "        sample1 = SingleTurnSample(\n",
    "            user_input=user_input,\n",
    "            response=response,\n",
    "            retrieved_contexts=retrieved_contexts,\n",
    "        )\n",
    "        score1 = await context_precision.single_turn_ascore(sample1)\n",
    "\n",
    "        sample2 = SingleTurnSample(\n",
    "            user_input=user_input,\n",
    "            retrieved_contexts=retrieved_contexts,\n",
    "        )\n",
    "        score2 = await scorer_relevance.single_turn_ascore(sample2)\n",
    "\n",
    "        sample3 = SingleTurnSample(\n",
    "            user_input=user_input,\n",
    "            response=response,\n",
    "            reference=reference\n",
    "        )\n",
    "        score3 = await scorer_accuracy.single_turn_ascore(sample3)\n",
    "\n",
    "        sample4 = SingleTurnSample(\n",
    "            response=response,\n",
    "            reference=reference\n",
    "        )\n",
    "        score4 = await scorer_similarity.single_turn_ascore(sample4)\n",
    "\n",
    "        sample5 = SingleTurnSample(\n",
    "            user_input=user_input,\n",
    "            response=response,\n",
    "            retrieved_contexts=retrieved_contexts,\n",
    "        )\n",
    "        score5 = await scorer_faithfulness.single_turn_ascore(sample5)\n",
    "\n",
    "        end_time = time.time()\n",
    "        evaluation_time = end_time - start_time\n",
    "\n",
    "        # 记录结果\n",
    "        results.append({\n",
    "            'Query': user_input,\n",
    "            'Ground_truth': reference,\n",
    "            'Response': response,\n",
    "            'Retrievaled_context': retrieved_context_str,\n",
    "            'Context_Precision': score1,\n",
    "            'Context_Relevance': score2,\n",
    "            'Answer_Accuracy': score3,\n",
    "            'Semantic_Similarity': score4,\n",
    "            'Faithfulness': score5,\n",
    "            'Evaluation_Time': evaluation_time\n",
    "        })\n",
    "\n",
    "    # 保存结果到新的 CSV 文件\n",
    "    output_df = pd.DataFrame(results)\n",
    "    output_file = 'evaluation_results.csv'\n",
    "    output_df.to_csv(output_file, index=False)\n",
    "    print(f\"Results saved to {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812dc3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\transformers\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "d:\\miniconda3\\envs\\transformers\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3517: UserWarning: WARNING! response_format is not default parameter.\n",
      "                response_format was transferred to model_kwargs.\n",
      "                Please confirm that response_format is what you intended.\n",
      "  if await self.run_code(code, result, async_=asy):\n",
      "C:\\Users\\11517\\AppData\\Local\\Temp\\ipykernel_21000\\1177550580.py:42: DeprecationWarning: LangchainEmbeddingsWrapper is deprecated and will be removed in a future version. Use the modern embedding providers instead: embedding_factory('openai', model='text-embedding-3-small', client=openai_client) or from ragas.embeddings import OpenAIEmbeddings, GoogleEmbeddings, HuggingFaceEmbeddings\n",
      "  evaluator_embeddings_wrapper = LangchainEmbeddingsWrapper(evaluator_embedding)\n",
      "评估进度:   5%|▌         | 1/19 [00:33<09:55, 33.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度:  11%|█         | 2/19 [01:03<08:54, 31.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度:  16%|█▌        | 3/19 [02:03<11:52, 44.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度:  21%|██        | 4/19 [02:37<10:07, 40.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度:  26%|██▋       | 5/19 [03:11<08:51, 37.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度:  32%|███▏      | 6/19 [03:50<08:19, 38.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度:  37%|███▋      | 7/19 [04:24<07:21, 36.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度:  42%|████▏     | 8/19 [04:56<06:29, 35.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度:  47%|████▋     | 9/19 [05:35<06:04, 36.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度:  53%|█████▎    | 10/19 [06:08<05:20, 35.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度:  58%|█████▊    | 11/19 [06:50<05:00, 37.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度:  63%|██████▎   | 12/19 [07:59<05:28, 46.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度:  68%|██████▊   | 13/19 [09:34<06:08, 61.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度:  74%|███████▎  | 14/19 [12:20<07:45, 93.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度:  79%|███████▉  | 15/19 [13:16<05:28, 82.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度:  84%|████████▍ | 16/19 [14:15<03:45, 75.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度:  89%|████████▉ | 17/19 [14:54<02:08, 64.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度:  95%|█████████▍| 18/19 [15:40<00:58, 58.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度: 100%|██████████| 19/19 [17:34<00:00, 55.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import pandas as pd\n",
    "import time\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "from ragas.dataset_schema import SingleTurnSample\n",
    "from ragas.metrics import (\n",
    "    LLMContextPrecisionWithoutReference,\n",
    "    ContextRelevance,\n",
    "    AnswerAccuracy,\n",
    "    SemanticSimilarity,\n",
    "    Faithfulness\n",
    ")\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "import openpyxl  # 确保安装 openpyxl 以支持 Excel 追加\n",
    "\n",
    "# 设置 API Key 和 Base URL\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your api key\"\n",
    "\n",
    "# 创建 LangChain LLM 实例，支持自定义 base_url，并强制 JSON 输出以修复解析错误\n",
    "llm_instance = ChatOpenAI(\n",
    "    model=\"deepseek-chat\",\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    base_url=\"your base url\",\n",
    "    response_format={\"type\": \"json_object\"}  # 强制 JSON 输出模式，修复 OutputParserException\n",
    ")\n",
    "\n",
    "# 包装成 Ragas LLM\n",
    "evaluator_llm = LangchainLLMWrapper(llm_instance)\n",
    "\n",
    "# 创建 LangChain 嵌入实例，使用 text-embedding-3-small 模型\n",
    "evaluator_embedding = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    base_url=\"your base url\",\n",
    ")\n",
    "\n",
    "# 包装成 Ragas 嵌入\n",
    "evaluator_embeddings_wrapper = LangchainEmbeddingsWrapper(evaluator_embedding)\n",
    "\n",
    "async def main():\n",
    "    # 读取输入 XLSX 文件\n",
    "    input_file = 'merged_test_dataset_1.xlsx'\n",
    "    df = pd.read_excel(input_file)\n",
    "\n",
    "    # 创建评估器（在循环外创建以复用）\n",
    "    context_precision = LLMContextPrecisionWithoutReference(llm=evaluator_llm)\n",
    "    scorer_relevance = ContextRelevance(llm=evaluator_llm)\n",
    "    scorer_accuracy = AnswerAccuracy(llm=evaluator_llm)\n",
    "    scorer_similarity = SemanticSimilarity(embeddings=evaluator_embeddings_wrapper)\n",
    "    scorer_faithfulness = Faithfulness(llm=evaluator_llm)\n",
    "\n",
    "    output_file = 'evaluation_results_1.xlsx'\n",
    "\n",
    "    # 如果输出文件不存在，创建空文件并写入表头\n",
    "    if not os.path.exists(output_file):\n",
    "        header_df = pd.DataFrame(columns=[\n",
    "            'Query', 'Ground_truth', 'Response', 'Retrievaled_context',\n",
    "            'Context_Precision', 'Context_Relevance', 'Answer_Accuracy',\n",
    "            'Semantic_Similarity', 'Faithfulness', 'Evaluation_Time'\n",
    "        ])\n",
    "        header_df.to_excel(output_file, index=False)\n",
    "\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df), desc=\"评估进度\"):\n",
    "        start_time = time.time()\n",
    "\n",
    "        user_input = row['Query']\n",
    "        reference = row['Ground_truth']\n",
    "        response = row['Response']\n",
    "        retrieved_context_str = row['Retrievaled_context']\n",
    "\n",
    "        # 尝试解析 retrieved_contexts 为列表，如果失败则视为单个字符串的列表\n",
    "        try:\n",
    "            retrieved_contexts = ast.literal_eval(retrieved_context_str)\n",
    "            if not isinstance(retrieved_contexts, list):\n",
    "                retrieved_contexts = [retrieved_context_str]\n",
    "        except:\n",
    "            retrieved_contexts = [retrieved_context_str]\n",
    "\n",
    "        # 创建样本并计算分数\n",
    "        sample1 = SingleTurnSample(\n",
    "            user_input=user_input,\n",
    "            response=response,\n",
    "            retrieved_contexts=retrieved_contexts,\n",
    "        )\n",
    "        score1 = await context_precision.single_turn_ascore(sample1)\n",
    "\n",
    "        sample2 = SingleTurnSample(\n",
    "            user_input=user_input,\n",
    "            retrieved_contexts=retrieved_contexts,\n",
    "        )\n",
    "        score2 = await scorer_relevance.single_turn_ascore(sample2)\n",
    "\n",
    "        sample3 = SingleTurnSample(\n",
    "            user_input=user_input,\n",
    "            response=response,\n",
    "            reference=reference\n",
    "        )\n",
    "        score3 = await scorer_accuracy.single_turn_ascore(sample3)\n",
    "\n",
    "        sample4 = SingleTurnSample(\n",
    "            response=response,\n",
    "            reference=reference\n",
    "        )\n",
    "        score4 = await scorer_similarity.single_turn_ascore(sample4)\n",
    "\n",
    "        sample5 = SingleTurnSample(\n",
    "            user_input=user_input,\n",
    "            response=response,\n",
    "            retrieved_contexts=retrieved_contexts,\n",
    "        )\n",
    "        score5 = await scorer_faithfulness.single_turn_ascore(sample5)\n",
    "\n",
    "        end_time = time.time()\n",
    "        evaluation_time = end_time - start_time\n",
    "\n",
    "        # 记录单行结果\n",
    "        result = {\n",
    "            'Query': user_input,\n",
    "            'Ground_truth': reference,\n",
    "            'Response': response,\n",
    "            'Retrievaled_context': retrieved_context_str,\n",
    "            'Context_Precision': score1,\n",
    "            'Context_Relevance': score2,\n",
    "            'Answer_Accuracy': score3,\n",
    "            'Semantic_Similarity': score4,\n",
    "            'Faithfulness': score5,\n",
    "            'Evaluation_Time': evaluation_time\n",
    "        }\n",
    "\n",
    "        # 将单行结果追加到 Excel 文件（使用 openpyxl 引擎支持追加），添加重试机制以处理 PermissionError\n",
    "        result_df = pd.DataFrame([result])\n",
    "        retries = 3\n",
    "        for attempt in range(retries):\n",
    "            try:\n",
    "                with pd.ExcelWriter(output_file, mode='a', engine='openpyxl', if_sheet_exists='overlay') as writer:\n",
    "                    # 读取现有行数\n",
    "                    book = writer.book\n",
    "                    sheet = book.active\n",
    "                    startrow = sheet.max_row\n",
    "                    # 追加数据（不包括表头）\n",
    "                    result_df.to_excel(writer, index=False, header=False, startrow=startrow)\n",
    "                print(f\"Row {index + 1} saved to {output_file}\")\n",
    "                break\n",
    "            except PermissionError:\n",
    "                print(f\"Permission denied on attempt {attempt + 1} for row {index + 1}. Please close the file if it's open. Retrying in 5 seconds...\")\n",
    "                time.sleep(5)\n",
    "        else:\n",
    "            raise PermissionError(f\"Failed to write to {output_file} after {retries} attempts. Ensure the file is closed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
