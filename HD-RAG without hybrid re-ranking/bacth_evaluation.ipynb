{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3108abc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import pandas as pd\n",
    "import time\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "from ragas.dataset_schema import SingleTurnSample\n",
    "from ragas.metrics import (\n",
    "    LLMContextPrecisionWithoutReference,\n",
    "    ContextRelevance,\n",
    "    AnswerAccuracy,\n",
    "    SemanticSimilarity,\n",
    "    Faithfulness\n",
    ")\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "# 设置 API Key 和 Base URL\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your api key\"\n",
    "\n",
    "# 创建 LangChain LLM 实例，支持自定义 base_url\n",
    "llm_instance = ChatOpenAI(\n",
    "    model=\"deepseek-chat\",\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    base_url=\"your base url\",\n",
    ")\n",
    "\n",
    "# 包装成 Ragas LLM\n",
    "evaluator_llm = LangchainLLMWrapper(llm_instance)\n",
    "\n",
    "# 创建 LangChain 嵌入实例，使用 text-embedding-3-small 模型\n",
    "evaluator_embedding = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    base_url=\"your base url\",\n",
    ")\n",
    "\n",
    "# 包装成 Ragas 嵌入\n",
    "evaluator_embeddings_wrapper = LangchainEmbeddingsWrapper(evaluator_embedding)\n",
    "\n",
    "async def main():\n",
    "    # 读取输入 CSV 文件\n",
    "    input_file = 'input.csv'\n",
    "    df = pd.read_csv(input_file)\n",
    "\n",
    "    # 创建评估器（在循环外创建以复用）\n",
    "    context_precision = LLMContextPrecisionWithoutReference(llm=evaluator_llm)\n",
    "    scorer_relevance = ContextRelevance(llm=evaluator_llm)\n",
    "    scorer_accuracy = AnswerAccuracy(llm=evaluator_llm)\n",
    "    scorer_similarity = SemanticSimilarity(embeddings=evaluator_embeddings_wrapper)\n",
    "    scorer_faithfulness = Faithfulness(llm=evaluator_llm)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df), desc=\"评估进度\"):\n",
    "        start_time = time.time()\n",
    "\n",
    "        user_input = row['Query']\n",
    "        reference = row['Ground_truth']\n",
    "        response = row['Response']\n",
    "        retrieved_context_str = row['Retrievaled_context']\n",
    "\n",
    "        # 尝试解析 retrieved_contexts 为列表，如果失败则视为单个字符串的列表\n",
    "        try:\n",
    "            retrieved_contexts = ast.literal_eval(retrieved_context_str)\n",
    "            if not isinstance(retrieved_contexts, list):\n",
    "                retrieved_contexts = [retrieved_context_str]\n",
    "        except:\n",
    "            retrieved_contexts = [retrieved_context_str]\n",
    "\n",
    "        # 创建样本并计算分数\n",
    "        sample1 = SingleTurnSample(\n",
    "            user_input=user_input,\n",
    "            response=response,\n",
    "            retrieved_contexts=retrieved_contexts,\n",
    "        )\n",
    "        score1 = await context_precision.single_turn_ascore(sample1)\n",
    "\n",
    "        sample2 = SingleTurnSample(\n",
    "            user_input=user_input,\n",
    "            retrieved_contexts=retrieved_contexts,\n",
    "        )\n",
    "        score2 = await scorer_relevance.single_turn_ascore(sample2)\n",
    "\n",
    "        sample3 = SingleTurnSample(\n",
    "            user_input=user_input,\n",
    "            response=response,\n",
    "            reference=reference\n",
    "        )\n",
    "        score3 = await scorer_accuracy.single_turn_ascore(sample3)\n",
    "\n",
    "        sample4 = SingleTurnSample(\n",
    "            response=response,\n",
    "            reference=reference\n",
    "        )\n",
    "        score4 = await scorer_similarity.single_turn_ascore(sample4)\n",
    "\n",
    "        sample5 = SingleTurnSample(\n",
    "            user_input=user_input,\n",
    "            response=response,\n",
    "            retrieved_contexts=retrieved_contexts,\n",
    "        )\n",
    "        score5 = await scorer_faithfulness.single_turn_ascore(sample5)\n",
    "\n",
    "        end_time = time.time()\n",
    "        evaluation_time = end_time - start_time\n",
    "\n",
    "        # 记录结果\n",
    "        results.append({\n",
    "            'Query': user_input,\n",
    "            'Ground_truth': reference,\n",
    "            'Response': response,\n",
    "            'Retrievaled_context': retrieved_context_str,\n",
    "            'Context_Precision': score1,\n",
    "            'Context_Relevance': score2,\n",
    "            'Answer_Accuracy': score3,\n",
    "            'Semantic_Similarity': score4,\n",
    "            'Faithfulness': score5,\n",
    "            'Evaluation_Time': evaluation_time\n",
    "        })\n",
    "\n",
    "    # 保存结果到新的 CSV 文件\n",
    "    output_df = pd.DataFrame(results)\n",
    "    output_file = 'evaluation_results.csv'\n",
    "    output_df.to_csv(output_file, index=False)\n",
    "    print(f\"Results saved to {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc72c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\miniconda3\\envs\\transformers\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3517: UserWarning: WARNING! response_format is not default parameter.\n",
      "                response_format was transferred to model_kwargs.\n",
      "                Please confirm that response_format is what you intended.\n",
      "  if await self.run_code(code, result, async_=asy):\n",
      "C:\\Users\\11517\\AppData\\Local\\Temp\\ipykernel_31112\\1177550580.py:42: DeprecationWarning: LangchainEmbeddingsWrapper is deprecated and will be removed in a future version. Use the modern embedding providers instead: embedding_factory('openai', model='text-embedding-3-small', client=openai_client) or from ragas.embeddings import OpenAIEmbeddings, GoogleEmbeddings, HuggingFaceEmbeddings\n",
      "  evaluator_embeddings_wrapper = LangchainEmbeddingsWrapper(evaluator_embedding)\n",
      "评估进度:   3%|▎         | 1/32 [01:40<51:57, 100.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度:   6%|▋         | 2/32 [02:47<40:24, 80.81s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度:   9%|▉         | 3/32 [03:26<29:55, 61.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 3 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度:  12%|█▎        | 4/32 [04:31<29:21, 62.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 4 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度:  16%|█▌        | 5/32 [05:01<23:00, 51.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 5 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度:  19%|█▉        | 6/32 [05:42<20:34, 47.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 6 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度:  22%|██▏       | 7/32 [06:13<17:38, 42.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 7 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度:  25%|██▌       | 8/32 [06:48<15:54, 39.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 8 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度:  28%|██▊       | 9/32 [07:26<15:03, 39.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 9 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度:  31%|███▏      | 10/32 [08:01<13:58, 38.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 10 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度:  34%|███▍      | 11/32 [08:53<14:50, 42.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 11 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度:  38%|███▊      | 12/32 [09:28<13:22, 40.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 12 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度:  41%|████      | 13/32 [09:55<11:22, 35.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 13 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度:  44%|████▍     | 14/32 [10:39<11:32, 38.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 14 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度:  47%|████▋     | 15/32 [11:14<10:35, 37.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 15 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度:  50%|█████     | 16/32 [11:33<08:30, 31.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 16 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度:  53%|█████▎    | 17/32 [11:57<07:23, 29.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 17 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度:  56%|█████▋    | 18/32 [12:23<06:38, 28.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 18 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度:  59%|█████▉    | 19/32 [12:55<06:23, 29.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 19 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度:  62%|██████▎   | 20/32 [13:35<06:31, 32.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 20 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度:  66%|██████▌   | 21/32 [13:57<05:25, 29.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 21 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度:  69%|██████▉   | 22/32 [14:25<04:50, 29.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 22 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度:  72%|███████▏  | 23/32 [14:55<04:23, 29.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 23 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度:  75%|███████▌  | 24/32 [16:16<05:58, 44.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 24 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度:  78%|███████▊  | 25/32 [17:00<05:10, 44.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 25 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度:  81%|████████▏ | 26/32 [18:09<05:11, 51.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 26 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度:  84%|████████▍ | 27/32 [19:07<04:28, 53.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 27 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度:  88%|████████▊ | 28/32 [19:39<03:09, 47.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 28 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度:  91%|█████████ | 29/32 [20:27<02:22, 47.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 29 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度:  94%|█████████▍| 30/32 [20:49<01:19, 39.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 30 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度:  97%|█████████▋| 31/32 [21:11<00:34, 34.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 31 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "评估进度: 100%|██████████| 32/32 [22:26<00:00, 42.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 32 saved to evaluation_results_1.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import asyncio\n",
    "import pandas as pd\n",
    "import time\n",
    "import ast\n",
    "from tqdm import tqdm\n",
    "from ragas.dataset_schema import SingleTurnSample\n",
    "from ragas.metrics import (\n",
    "    LLMContextPrecisionWithoutReference,\n",
    "    ContextRelevance,\n",
    "    AnswerAccuracy,\n",
    "    SemanticSimilarity,\n",
    "    Faithfulness\n",
    ")\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "import openpyxl  # 确保安装 openpyxl 以支持 Excel 追加\n",
    "\n",
    "# 设置 API Key 和 Base URL\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your api key\"\n",
    "\n",
    "# 创建 LangChain LLM 实例，支持自定义 base_url，并强制 JSON 输出以修复解析错误\n",
    "llm_instance = ChatOpenAI(\n",
    "    model=\"deepseek-chat\",\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    base_url=\"your base url\",\n",
    "    response_format={\"type\": \"json_object\"}  # 强制 JSON 输出模式，修复 OutputParserException\n",
    ")\n",
    "\n",
    "# 包装成 Ragas LLM\n",
    "evaluator_llm = LangchainLLMWrapper(llm_instance)\n",
    "\n",
    "# 创建 LangChain 嵌入实例，使用 text-embedding-3-small 模型\n",
    "evaluator_embedding = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    base_url=\"your base url\",\n",
    ")\n",
    "\n",
    "# 包装成 Ragas 嵌入\n",
    "evaluator_embeddings_wrapper = LangchainEmbeddingsWrapper(evaluator_embedding)\n",
    "\n",
    "async def main():\n",
    "    # 读取输入 XLSX 文件\n",
    "    input_file = 'merged_test_dataset_1.xlsx'\n",
    "    df = pd.read_excel(input_file)\n",
    "\n",
    "    # 创建评估器（在循环外创建以复用）\n",
    "    context_precision = LLMContextPrecisionWithoutReference(llm=evaluator_llm)\n",
    "    scorer_relevance = ContextRelevance(llm=evaluator_llm)\n",
    "    scorer_accuracy = AnswerAccuracy(llm=evaluator_llm)\n",
    "    scorer_similarity = SemanticSimilarity(embeddings=evaluator_embeddings_wrapper)\n",
    "    scorer_faithfulness = Faithfulness(llm=evaluator_llm)\n",
    "\n",
    "    output_file = 'evaluation_results_1.xlsx'\n",
    "\n",
    "    # 如果输出文件不存在，创建空文件并写入表头\n",
    "    if not os.path.exists(output_file):\n",
    "        header_df = pd.DataFrame(columns=[\n",
    "            'Query', 'Ground_truth', 'Response', 'Retrievaled_context',\n",
    "            'Context_Precision', 'Context_Relevance', 'Answer_Accuracy',\n",
    "            'Semantic_Similarity', 'Faithfulness', 'Evaluation_Time'\n",
    "        ])\n",
    "        header_df.to_excel(output_file, index=False)\n",
    "\n",
    "    for index, row in tqdm(df.iterrows(), total=len(df), desc=\"评估进度\"):\n",
    "        start_time = time.time()\n",
    "\n",
    "        user_input = row['Query']\n",
    "        reference = row['Ground_truth']\n",
    "        response = row['Response']\n",
    "        retrieved_context_str = row['Retrievaled_context']\n",
    "\n",
    "        # 尝试解析 retrieved_contexts 为列表，如果失败则视为单个字符串的列表\n",
    "        try:\n",
    "            retrieved_contexts = ast.literal_eval(retrieved_context_str)\n",
    "            if not isinstance(retrieved_contexts, list):\n",
    "                retrieved_contexts = [retrieved_context_str]\n",
    "        except:\n",
    "            retrieved_contexts = [retrieved_context_str]\n",
    "\n",
    "        # 创建样本并计算分数\n",
    "        sample1 = SingleTurnSample(\n",
    "            user_input=user_input,\n",
    "            response=response,\n",
    "            retrieved_contexts=retrieved_contexts,\n",
    "        )\n",
    "        score1 = await context_precision.single_turn_ascore(sample1)\n",
    "\n",
    "        sample2 = SingleTurnSample(\n",
    "            user_input=user_input,\n",
    "            retrieved_contexts=retrieved_contexts,\n",
    "        )\n",
    "        score2 = await scorer_relevance.single_turn_ascore(sample2)\n",
    "\n",
    "        sample3 = SingleTurnSample(\n",
    "            user_input=user_input,\n",
    "            response=response,\n",
    "            reference=reference\n",
    "        )\n",
    "        score3 = await scorer_accuracy.single_turn_ascore(sample3)\n",
    "\n",
    "        sample4 = SingleTurnSample(\n",
    "            response=response,\n",
    "            reference=reference\n",
    "        )\n",
    "        score4 = await scorer_similarity.single_turn_ascore(sample4)\n",
    "\n",
    "        sample5 = SingleTurnSample(\n",
    "            user_input=user_input,\n",
    "            response=response,\n",
    "            retrieved_contexts=retrieved_contexts,\n",
    "        )\n",
    "        score5 = await scorer_faithfulness.single_turn_ascore(sample5)\n",
    "\n",
    "        end_time = time.time()\n",
    "        evaluation_time = end_time - start_time\n",
    "\n",
    "        # 记录单行结果\n",
    "        result = {\n",
    "            'Query': user_input,\n",
    "            'Ground_truth': reference,\n",
    "            'Response': response,\n",
    "            'Retrievaled_context': retrieved_context_str,\n",
    "            'Context_Precision': score1,\n",
    "            'Context_Relevance': score2,\n",
    "            'Answer_Accuracy': score3,\n",
    "            'Semantic_Similarity': score4,\n",
    "            'Faithfulness': score5,\n",
    "            'Evaluation_Time': evaluation_time\n",
    "        }\n",
    "\n",
    "        # 将单行结果追加到 Excel 文件（使用 openpyxl 引擎支持追加），添加重试机制以处理 PermissionError\n",
    "        result_df = pd.DataFrame([result])\n",
    "        retries = 3\n",
    "        for attempt in range(retries):\n",
    "            try:\n",
    "                with pd.ExcelWriter(output_file, mode='a', engine='openpyxl', if_sheet_exists='overlay') as writer:\n",
    "                    # 读取现有行数\n",
    "                    book = writer.book\n",
    "                    sheet = book.active\n",
    "                    startrow = sheet.max_row\n",
    "                    # 追加数据（不包括表头）\n",
    "                    result_df.to_excel(writer, index=False, header=False, startrow=startrow)\n",
    "                print(f\"Row {index + 1} saved to {output_file}\")\n",
    "                break\n",
    "            except PermissionError:\n",
    "                print(f\"Permission denied on attempt {attempt + 1} for row {index + 1}. Please close the file if it's open. Retrying in 5 seconds...\")\n",
    "                time.sleep(5)\n",
    "        else:\n",
    "            raise PermissionError(f\"Failed to write to {output_file} after {retries} attempts. Ensure the file is closed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
